{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:13:08.178344100Z",
     "start_time": "2024-06-08T07:13:07.127527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "d3144d2f9f2ecd01",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\A1D5688\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\A1D5688\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\A1D5688\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources if not already downloaded\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T07:13:08.374013600Z",
     "start_time": "2024-06-08T07:13:08.171797600Z"
    }
   },
   "id": "c428ae07f926bf97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:13:09.160855700Z",
     "start_time": "2024-06-08T07:13:08.374013600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a pandas DataFrame\n",
    "csv_file = r'IMDB Dataset.csv'\n",
    "df = pd.read_csv(csv_file)"
   ],
   "id": "c857b0ad7bdd67e2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "stop_words1 = list(stopwords.words('english'))\n",
    "specific_words1 = [\"br\", \"positive\", \"negative\",\"stupid\", \"horrible\", \"ever\", \"even\", \"waste\", \"movie\", \"one\",\"story\", \"movies\", \"book\", \"film\", \"show\", \"good\", \"bad\", \"worst\", \"episode\", \"tv\", \"watch\", \"series\", \"really\", \"great\", \"like\", \"would\", \"see\", \"well\", \"people\", \"much\", \"get\", \"think\", \"movie\", \"movies\", \"film\", \"films\", \"the\", \"a\", \"and\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"will\", \"would\", \"shall\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"don\", \"shouldn\", \"wasn\", \"weren\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"will\", \"would\", \"shall\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"dont\", \"shouldnt\", \"wasnt\", \"werent\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"will\", \"would\", \"shall\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"aint\", \"isnt\", \"arent\", \"cant\", \"couldnt\", \"didnt\", \"doesnt\", \"hadnt\", \"hasnt\", \"havent\", \"wasnt\", \"werent\", \"wont\", \"wouldnt\", \"am\", \"are\", \"as\", \"at\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"will\", \"would\", \"shall\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"i\", \"me\", \"my\", \"mine\", \"you\", \"your\", \"yours\", \"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"it\", \"its\", \"we\", \"us\", \"our\", \"ours\", \"they\", \"them\", \"their\", \"theirs\", \"what\", \"which\", \"who\", \"whom\", \"whose\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"will\", \"would\", \"shall\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"will\", \"would\", \"shall\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\", \"just\", \"only\", \"also\", \"another\", \"any\", \"each\", \"few\", \"more\", \"most\", \"other\", \"several\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"now\", \"soon\", \"then\", \"after\", \"again\", \"already\", \"as\", \"before\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"several\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"several\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"all\", \"another\", \"any\", \"each\", \"few\", \"more\", \"most\", \"other\", \"several\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"about\", \"above\", \"across\", \"after\", \"again\", \"against\", \"along\", \"amid\", \"amidst\", \"among\", \"amongst\", \"around\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\", \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"circa\", \"despite\", \"down\", \"during\", \"except\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\", \"near\", \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"out\", \"outside\", \"over\", \"past\", \"per\", \"plus\", \"regarding\", \"round\", \"save\", \"since\", \"than\", \"through\", \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\", \"up\", \"upon\", \"versus\", \"via\"]\n",
    "stop_words = stop_words1+specific_words1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T07:13:09.181931400Z",
     "start_time": "2024-06-08T07:13:09.176501400Z"
    }
   },
   "id": "4f3b35fb66a77b52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:13:16.489973800Z",
     "start_time": "2024-06-08T07:13:09.181931400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(df['review'])"
   ],
   "id": "c5858523b409646",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:13:17.837166400Z",
     "start_time": "2024-06-08T07:13:16.489973800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform truncated SVD\n",
    "svd = TruncatedSVD(n_components=5)\n",
    "decomposed_matrix = svd.fit_transform(X)"
   ],
   "id": "2e5a60841d18cc67",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:13:17.971170600Z",
     "start_time": "2024-06-08T07:13:17.837166400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get topics\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "topic_weights = svd.components_\n",
    "topics = []\n",
    "for i, topic_weights_ in enumerate(topic_weights):\n",
    "    top_terms = [terms[idx] for idx in topic_weights_.argsort()[:-10:-1]]\n",
    "    topics.append(top_terms)"
   ],
   "id": "8175cbed10f118ba",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:13:17.986053600Z",
     "start_time": "2024-06-08T07:13:17.978565300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print topics\n",
    "for i, topic in enumerate(topics):\n",
    "    print(f\"Topic {i+1}:\")\n",
    "    print(\", \".join(topic))"
   ],
   "id": "1850fc65b8c3daa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "time, first, made, make, seen, acting, characters, way, plot\n",
      "Topic 2:\n",
      "horror, acting, plot, effects, terrible, budget, awful, watching, seen\n",
      "Topic 3:\n",
      "funny, love, comedy, saw, time, seen, watching, laugh, watched\n",
      "Topic 4:\n",
      "horror, kids, old, guy, girl, family, man, house, back\n",
      "Topic 5:\n",
      "funny, comedy, character, guy, jokes, laugh, characters, humor, plot\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
